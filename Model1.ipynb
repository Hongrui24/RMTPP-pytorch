{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyf2T703GKnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from scipy import integrate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i67P-BTsroL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "# Model for Recurrent Marked Temporal Point Process. Based on\n",
        "# Nan, Du et al Recurrent Marked Temporal Point Processes: Embedding Event\n",
        "# History to Vector.\n",
        "# This is a pytorch implementation of his model\n",
        "class RMTPP(nn.Module):\n",
        "    # input type_dim: dimension of types, which is a one-hot representation\n",
        "    # input hidden_dim: dimension of the hidden layer. Default is 1.\n",
        "    # input n_layers: number of hidden layers. Default is 1.\n",
        "    # This will initialize the recurrent neural network.\n",
        "    def __init__(self, type_dim, hidden_dim=1, n_layers=1):\n",
        "        super(RMTPP,self).__init__()\n",
        "        self.type_dim = type_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        # linear embedding layer: map from one-hot types to a number.\n",
        "        self.type_emb = nn.Linear(self.type_dim, 1, bias=True)\n",
        "        # recurrence layer: use of relu function, and the input are time and type\n",
        "        self.rnn = nn.RNN(input_size=2, hidden_size=self.hidden_dim, num_layers=self.n_layers,\n",
        "                          nonlinearity='relu', bias=True, batch_first=True)\n",
        "        # type generation layer: map from hidden layers to a vector representation of types\n",
        "        self.type_gen = nn.Linear(self.hidden_dim, self.type_dim, bias=True)\n",
        "        # time generation layers: map time and hidden layers to generate time\n",
        "        self.time_linear = nn.Linear(self.hidden_dim+1, 1, bias=True)\n",
        "\n",
        "    # This is the forward step of neural network\n",
        "    # Assume both the input has dim(batch, times, features) of dimension 3\n",
        "    # input whole_time_info: all of the time information\n",
        "    # input marker_info: training information for marker\n",
        "    def forward(self, train_time, marker_info):\n",
        "        marker1 = self.type_emb(marker_info)\n",
        "        combi_inputs = torch.cat((train_time, marker1), dim=-1)\n",
        "        out, hidden = self.rnn(combi_inputs)\n",
        "        out1 = out.contiguous().view(-1, self.hidden_dim)\n",
        "        type_guess = self.type_gen(out1)\n",
        "        return type_guess, out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTZ5Zu7n5_xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, whole_time_info, event_type, n_features,lr=0.01, n_epochs=1000):\n",
        "    for parameter in model.parameters():\n",
        "        parameter.data.fill_(random.uniform(-1,1))\n",
        "    marker_info, marker_target, whole_marker = type_encode(event_type, n_features)\n",
        "    train_time, whole_time_info = time_encode(whole_time_info)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        optimizer.zero_grad()\n",
        "        train_time.to(device)\n",
        "        marker_info.to(device)\n",
        "        type_out, hidden_out = model(train_time, marker_info)\n",
        "        marker_target = torch.reshape(marker_target, (-1,))\n",
        "        time_diff = whole_time_info[:, 1:, :] - whole_time_info[:, :-1, :]\n",
        "        combi_input_time = torch.cat((hidden_out, time_diff), dim=-1)\n",
        "        cif = model.time_linear(combi_input_time)\n",
        "        hidden_out = torch.reshape(hidden_out, (-1, model.hidden_dim))\n",
        "        cif = torch.reshape(cif,(-1, 1))\n",
        "        cif_weight = list(model.time_linear.parameters())\n",
        "        loss = criterion(type_out, marker_target) + my_loss(cif, cif_weight, hidden_out)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch%100 == 0:\n",
        "            print(\"Loss: {}\".format(loss.item()))\n",
        "\n",
        "\n",
        "def my_loss(cif, cif_weight, hidden_out):\n",
        "    loss = torch.mean(cif+torch.exp(torch.mm(hidden_out,cif_weight[0][:,:-1].transpose(0,1))\n",
        "                         + cif_weight[1][0])/cif_weight[0][0][-1]-torch.exp(cif)/cif_weight[0][0][-1])\n",
        "\n",
        "    return -loss\n",
        "\n",
        "\n",
        "def type_encode(event_type, numb_features):\n",
        "    event_type_arr = np.array(event_type)\n",
        "    type_s =np.zeros((len(event_type_arr), len(event_type_arr[0]), numb_features), dtype=np.float32)\n",
        "    for i in range(len(event_type_arr)):\n",
        "        for j in range(len(event_type_arr[0])):\n",
        "            type_s[i][j][event_type_arr[i][j]] = 1\n",
        "    type_s = torch.from_numpy(type_s)\n",
        "    return type_s[:,:-1,:], torch.tensor(event_type_arr)[:,1:], type_s\n",
        "\n",
        "\n",
        "def time_encode(time):\n",
        "    time_info = np.zeros((len(time), len(time[0]), 1), dtype=np.float32)\n",
        "    for i in range(len(time)):\n",
        "        for j in range(len(time[i])):\n",
        "            time_info[i][j][0] = time[i][j]\n",
        "    time_for_train = torch.from_numpy(time_info[:, :-1, :])\n",
        "    whole_time = torch.from_numpy(time_info)\n",
        "    return time_for_train, whole_time\n",
        "\n",
        "\n",
        "def make_time_target(time_sample):\n",
        "    time_target = torch.zeros(len(time_sample), len(time_sample[0]))\n",
        "    return time_target\n",
        "\n",
        "\n",
        "def predict(model, device, time, marker, n_features):\n",
        "    time = [time]\n",
        "    marker = [marker]\n",
        "    time_input = time_encode(time)[1]\n",
        "    type_input = type_encode(marker, n_features)[2]\n",
        "    type_input.to(device)\n",
        "    time_input.to(device)\n",
        "    type_out, hidden_out = model(time_input, type_input)\n",
        "    type_out = nn.functional.softmax(type_out[-1], dim=0)\n",
        "    type_int = torch.max(type_out, dim=0)[1].item()\n",
        "    estimated_time = cal_integral(model, hidden_out[0][-1][0], time_input[0][-1][0])\n",
        "    return type_int, estimated_time\n",
        "\n",
        "\n",
        "def cal_integral(model, hidden_out, time):\n",
        "    hidden_out = hidden_out.item()\n",
        "    parameters = list(model.time_linear.parameters())\n",
        "    bias = parameters[1][0].item()\n",
        "    v = parameters[0][0][0].item()\n",
        "    w = parameters[0][0][1].item()\n",
        "    func = lambda x: equation(x, time, hidden_out, bias, v, w)\n",
        "    y = integrate.quad(func, time, np.inf)\n",
        "    return y[0]\n",
        "\n",
        "\n",
        "def equation(time_var, start_time, hidden_out, bias, v, w):\n",
        "    time_guess = time_var*np.exp(v*hidden_out + w*(time_var-start_time)\n",
        "                                 + bias+np.exp(v*hidden_out+bias)/w\n",
        "                                 - np.exp(v*hidden_out + w*(time_var-start_time)+bias)/w)\n",
        "    return time_guess\n",
        "\n",
        "\n",
        "def select_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(\"You are using GPU acceleration.\")\n",
        "        print(\"Number of CUDAs(cores): \", torch.cuda.device_count())\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"CUDA is not Available. You are using CPU only.\")\n",
        "        print(\"Number of cores: \", os.cpu_count())\n",
        "    return device\n",
        "\n",
        "\n",
        "def data_process(file_name):\n",
        "    f = open('time-train.txt','r')\n",
        "    time_data = []\n",
        "    file_data = f.readlines()\n",
        "    f.close()\n",
        "    for line in file_data:\n",
        "        data = line.split(\" \")\n",
        "        a_list = []\n",
        "        for i in range(len(data)):\n",
        "            if data[i] != \"\\n\":\n",
        "                a_list.append(float(data[i]))\n",
        "        time_data.append(a_list)\n",
        "    return time_data\n",
        "\n",
        "\n",
        "def generate_type(time_data):\n",
        "    type_data = []\n",
        "    for line in time_data:\n",
        "      new_line = []\n",
        "      for item in line:\n",
        "          new_line.append(1)\n",
        "      type_data.append(new_line)\n",
        "    return type_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG58jKO9ojUI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 218
        },
        "outputId": "8d8c0720-edd6-4c78-c110-7920e8280238"
      },
      "source": [
        "time_data = data_process(\"time_train.txt\")\n",
        "type_data = generate_type(time_data)\n",
        "model = RMTPP(2)\n",
        "device = select_device()\n",
        "train(model, device, time_data, type_data, 2)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are using GPU acceleration.\n",
            "Number of CUDAs(cores):  1\n",
            "Loss: 0.261820912361145\n",
            "Loss: -0.4017449617385864\n",
            "Loss: -0.5356290340423584\n",
            "Loss: -0.5663974285125732\n",
            "Loss: -0.583436131477356\n",
            "Loss: -0.5932741165161133\n",
            "Loss: -0.5990686416625977\n",
            "Loss: -0.6025647521018982\n",
            "Loss: -0.6048175692558289\n",
            "Loss: -0.606339693069458\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugQ8eub46qE7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        },
        "outputId": "e35616c8-d824-46f8-9830-26635d103af4"
      },
      "source": [
        "torch.save(model, \"model.pt\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type RMTPP. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    }
  ]
}