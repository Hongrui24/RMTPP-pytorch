{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Model1.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dyf2T703GKnO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import numpy as np\n",
        "import random\n",
        "from scipy import integrate"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_i67P-BTsroL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.autograd.set_detect_anomaly(True)\n",
        "# Model for Recurrent Marked Temporal Point Process. Based on\n",
        "# Nan, Du et al Recurrent Marked Temporal Point Processes: Embedding Event\n",
        "# History to Vector.\n",
        "# This is a pytorch implementation of his model\n",
        "class RMTPP(nn.Module):\n",
        "    # input type_dim: dimension of types, which is a one-hot representation\n",
        "    # input hidden_dim: dimension of the hidden layer. Default is 1.\n",
        "    # input n_layers: number of hidden layers. Default is 1.\n",
        "    # This will initialize the recurrent neural network.\n",
        "    def __init__(self, type_dim, hidden_dim=1, n_layers=1):\n",
        "        super(RMTPP,self).__init__()\n",
        "        self.type_dim = type_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "        # linear embedding layer: map from one-hot types to a number.\n",
        "        self.type_emb = nn.Linear(self.type_dim, 1, bias=True)\n",
        "        # recurrence layer: use of relu function, and the input are time and type\n",
        "        self.rnn = nn.RNN(input_size=2, hidden_size=self.hidden_dim, num_layers=self.n_layers,\n",
        "                          nonlinearity='relu', bias=True, batch_first=True)\n",
        "        # type generation layer: map from hidden layers to a vector representation of types\n",
        "        self.type_gen = nn.Linear(self.hidden_dim, self.type_dim, bias=True)\n",
        "        # time generation layers: map time and hidden layers to generate time\n",
        "        self.time_linear = nn.Linear(self.hidden_dim+1, 1, bias=True)\n",
        "\n",
        "    # This is the forward step of neural network\n",
        "    # Assume both the input has dim(batch, times, features) of dimension 3\n",
        "    # input whole_time_info: all of the time information\n",
        "    # input marker_info: training information for marker\n",
        "    def forward(self, train_time, marker_info):\n",
        "        marker1 = self.type_emb(marker_info)\n",
        "        combi_inputs = torch.cat((train_time, marker1), dim=-1)\n",
        "        out, hidden = self.rnn(combi_inputs)\n",
        "        out1 = out.contiguous().view(-1, self.hidden_dim)\n",
        "        type_guess = self.type_gen(out1)\n",
        "        return type_guess, out"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lTZ5Zu7n5_xy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train(model, device, whole_time_info, event_type, n_features,lr=0.01, n_epochs=1000):\n",
        "    for parameter in model.parameters():\n",
        "        parameter.data.fill_(random.uniform(-0.1,0.1))\n",
        "    marker_info, marker_target, whole_marker = type_encode(event_type, n_features)\n",
        "    train_time, whole_time_info = time_encode(whole_time_info)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "    for epoch in range(1, n_epochs+1):\n",
        "        optimizer.zero_grad()\n",
        "        train_time.to(device)\n",
        "        marker_info.to(device)\n",
        "        type_out, hidden_out = model(train_time, marker_info)\n",
        "        marker_target = torch.reshape(marker_target, (-1,))\n",
        "        time_diff = whole_time_info[:, 1:, :] - whole_time_info[:, :-1, :]\n",
        "        combi_input_time = torch.cat((hidden_out, time_diff), dim=-1)\n",
        "        cif = model.time_linear(combi_input_time)\n",
        "        hidden_out = torch.reshape(hidden_out, (-1, model.hidden_dim))\n",
        "        cif = torch.reshape(cif,(-1, 1))\n",
        "        cif_weight = list(model.time_linear.parameters())\n",
        "        loss = criterion(type_out, marker_target) + my_loss(cif, cif_weight, hidden_out)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if epoch%10 == 0:\n",
        "            print(\"Loss: {}\".format(loss.item()))\n",
        "\n",
        "\n",
        "def my_loss(cif, cif_weight, hidden_out):\n",
        "    loss = torch.sum(cif+torch.exp(torch.mm(hidden_out,cif_weight[0][:,:-1].transpose(0,1))\n",
        "                         + cif_weight[1][0])/cif_weight[0][0][-1]-torch.exp(cif)/cif_weight[0][0][-1])\n",
        "\n",
        "    return -loss\n",
        "\n",
        "\n",
        "def type_encode(event_type, numb_features):\n",
        "    event_type_arr = np.array(event_type)\n",
        "    type_s =np.zeros((len(event_type_arr), len(event_type_arr[0]), numb_features), dtype=np.float32)\n",
        "    for i in range(len(event_type_arr)):\n",
        "        for j in range(len(event_type_arr[0])):\n",
        "            type_s[i][j][event_type_arr[i][j]] = 1\n",
        "    type_s = torch.from_numpy(type_s)\n",
        "    return type_s[:,:-1,:], torch.tensor(event_type_arr)[:,1:], type_s\n",
        "\n",
        "\n",
        "def time_encode(time):\n",
        "    time_info = np.zeros((len(time), len(time[0]), 1), dtype=np.float32)\n",
        "    for i in range(len(time)):\n",
        "        for j in range(len(time[i])):\n",
        "            time_info[i][j][0] = time[i][j]\n",
        "    time_for_train = torch.from_numpy(time_info[:, :-1, :])\n",
        "    whole_time = torch.from_numpy(time_info)\n",
        "    return time_for_train, whole_time\n",
        "\n",
        "\n",
        "def make_time_target(time_sample):\n",
        "    time_target = torch.zeros(len(time_sample), len(time_sample[0]))\n",
        "    return time_target\n",
        "\n",
        "\n",
        "def predict(model, device, time, marker, n_features):\n",
        "    time = [time]\n",
        "    marker = [marker]\n",
        "    time_input = time_encode(time)[1]\n",
        "    type_input = type_encode(marker, n_features)[2]\n",
        "    type_input.to(device)\n",
        "    time_input.to(device)\n",
        "    type_out, hidden_out = model(time_input, type_input)\n",
        "    type_out = nn.functional.softmax(type_out[-1], dim=0)\n",
        "    type_int = torch.max(type_out, dim=0)[1].item()\n",
        "    estimated_time = cal_integral(model, hidden_out[0][-1][0], time_input[0][-1][0])\n",
        "    return type_int, estimated_time\n",
        "\n",
        "\n",
        "def cal_integral(model, hidden_out, time):\n",
        "    hidden_out = hidden_out.item()\n",
        "    parameters = list(model.time_linear.parameters())\n",
        "    bias = parameters[1][0].item()\n",
        "    v = parameters[0][0][0].item()\n",
        "    w = parameters[0][0][1].item()\n",
        "    func = lambda x: equation(x, time, hidden_out, bias, v, w)\n",
        "    y = integrate.quad(func, time, np.inf)\n",
        "    return y[0]\n",
        "\n",
        "\n",
        "def equation(time_var, start_time, hidden_out, bias, v, w):\n",
        "    time_guess = time_var*np.exp(v*hidden_out + w*(time_var-start_time)\n",
        "                                 + bias+np.exp(v*hidden_out+bias)/w\n",
        "                                 - np.exp(v*hidden_out + w*(time_var-start_time)+bias)/w)\n",
        "    return time_guess\n",
        "\n",
        "\n",
        "def select_device():\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device('cuda')\n",
        "        print(\"You are using GPU acceleration.\")\n",
        "        print(\"Number of CUDAs(cores): \", torch.cuda.device_count())\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "        print(\"CUDA is not Available. You are using CPU only.\")\n",
        "        print(\"Number of cores: \", os.cpu_count())\n",
        "    return device\n",
        "\n",
        "\n",
        "def data_process(file_name):\n",
        "    f = open(file_name,'r')\n",
        "    time_data = []\n",
        "    file_data = f.readlines()\n",
        "    f.close()\n",
        "    for line in file_data:\n",
        "        data = line.split(\" \")\n",
        "        a_list = []\n",
        "        for i in range(len(data)):\n",
        "            if data[i] != \"\\n\":\n",
        "                a_list.append(float(data[i]))\n",
        "        time_data.append(a_list)\n",
        "    return time_data\n",
        "\n",
        "\n",
        "def generate_type(time_data):\n",
        "    type_data = []\n",
        "    for line in time_data:\n",
        "      new_line = []\n",
        "      for item in line:\n",
        "          new_line.append(1)\n",
        "      type_data.append(new_line)\n",
        "    return type_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG58jKO9ojUI",
        "colab_type": "code",
        "outputId": "d05d57e7-2b94-46e6-c4b5-190f367132cb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "time_data = data_process(\"time-train.txt\")\n",
        "type_data = generate_type(time_data)\n",
        "model = RMTPP(2)\n",
        "device = select_device()\n",
        "train(model, device, time_data, type_data, 2, n_epochs=1000)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are using GPU acceleration.\n",
            "Number of CUDAs(cores):  1\n",
            "Loss: 17437.712890625\n",
            "Loss: 10511.39453125\n",
            "Loss: 3677.794189453125\n",
            "Loss: -2928.800048828125\n",
            "Loss: -9239.0078125\n",
            "Loss: -15138.7001953125\n",
            "Loss: -20689.84765625\n",
            "Loss: -26296.38671875\n",
            "Loss: -31094.5078125\n",
            "Loss: -35297.75\n",
            "Loss: -38989.65625\n",
            "Loss: -42201.8125\n",
            "Loss: -44954.79296875\n",
            "Loss: -47271.50390625\n",
            "Loss: -49179.66015625\n",
            "Loss: -50715.48046875\n",
            "Loss: -51922.21484375\n",
            "Loss: -52846.546875\n",
            "Loss: -53534.87890625\n",
            "Loss: -54033.3671875\n",
            "Loss: -54383.78125\n",
            "Loss: -54622.66796875\n",
            "Loss: -54780.9375\n",
            "Loss: -54883.296875\n",
            "Loss: -54948.03125\n",
            "Loss: -54987.671875\n",
            "Loss: -55011.59765625\n",
            "Loss: -55025.625\n",
            "Loss: -55033.796875\n",
            "Loss: -55038.74609375\n",
            "Loss: -55041.8828125\n",
            "Loss: -55043.9453125\n",
            "Loss: -55045.66015625\n",
            "Loss: -55047.109375\n",
            "Loss: -55048.26171875\n",
            "Loss: -55049.78125\n",
            "Loss: -55051.0390625\n",
            "Loss: -55052.28125\n",
            "Loss: -55053.62890625\n",
            "Loss: -55054.89453125\n",
            "Loss: -55056.26171875\n",
            "Loss: -55057.75390625\n",
            "Loss: -55059.02734375\n",
            "Loss: -55060.50390625\n",
            "Loss: -55062.05859375\n",
            "Loss: -55063.609375\n",
            "Loss: -55065.0703125\n",
            "Loss: -55066.625\n",
            "Loss: -55067.88671875\n",
            "Loss: -55069.1015625\n",
            "Loss: -55070.34765625\n",
            "Loss: -55071.61328125\n",
            "Loss: -55073.03125\n",
            "Loss: -55074.25390625\n",
            "Loss: -55075.65625\n",
            "Loss: -55076.89453125\n",
            "Loss: -55078.28515625\n",
            "Loss: -55079.79296875\n",
            "Loss: -55081.046875\n",
            "Loss: -55082.6796875\n",
            "Loss: -55083.98828125\n",
            "Loss: -55085.66796875\n",
            "Loss: -55086.78515625\n",
            "Loss: -55088.0859375\n",
            "Loss: -55089.3125\n",
            "Loss: -55090.52734375\n",
            "Loss: -55091.62890625\n",
            "Loss: -55092.73046875\n",
            "Loss: -55093.95703125\n",
            "Loss: -55095.16015625\n",
            "Loss: -55096.3671875\n",
            "Loss: -55097.5\n",
            "Loss: -55098.84765625\n",
            "Loss: -55099.8984375\n",
            "Loss: -55101.13671875\n",
            "Loss: -55102.359375\n",
            "Loss: -55103.67578125\n",
            "Loss: -55104.90234375\n",
            "Loss: -55106.24609375\n",
            "Loss: -55107.3984375\n",
            "Loss: -55108.39453125\n",
            "Loss: -55109.5\n",
            "Loss: -55110.44921875\n",
            "Loss: -55111.61328125\n",
            "Loss: -55112.70703125\n",
            "Loss: -55113.8125\n",
            "Loss: -55114.91796875\n",
            "Loss: -55116.05859375\n",
            "Loss: -55116.9921875\n",
            "Loss: -55118.01953125\n",
            "Loss: -55118.94140625\n",
            "Loss: -55120.078125\n",
            "Loss: -55121.046875\n",
            "Loss: -55122.109375\n",
            "Loss: -55123.1796875\n",
            "Loss: -55124.109375\n",
            "Loss: -55125.0078125\n",
            "Loss: -55125.72265625\n",
            "Loss: -55126.5703125\n",
            "Loss: -55127.32421875\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugQ8eub46qE7",
        "colab_type": "code",
        "outputId": "fcc8c610-29e1-480d-a87c-a5ac5788c2f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "torch.save(model, \"model.pt\")"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/serialization.py:402: UserWarning: Couldn't retrieve source code for container of type RMTPP. It won't be checked for correctness upon loading.\n",
            "  \"type \" + obj.__name__ + \". It won't be checked \"\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7c13VH8xtec",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = torch.load(\"model.pt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9EZfxw2Tx64y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 138
        },
        "outputId": "332e58a7-2c0f-49cb-939d-9bd43ee4b01c"
      },
      "source": [
        "time_data = data_process(\"time-test.txt\")\n",
        "type_data = generate_type(time_data)\n",
        "time_data = time_data[0][0:56]\n",
        "type_data = type_data[0][0:56]\n",
        "device = select_device()\n",
        "for i in range(100):\n",
        "  pred_type, pred_time = predict(model, device, time_data, type_data, 2)\n",
        "  time_data.append(pred_time)\n",
        "  type_data.append(pred_type)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "You are using GPU acceleration.\n",
            "Number of CUDAs(cores):  1\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:87: RuntimeWarning: overflow encountered in exp\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:80: IntegrationWarning: The occurrence of roundoff error is detected, which prevents \n",
            "  the requested tolerance from being achieved.  The error may be \n",
            "  underestimated.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pWARsmnQzZkS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "47f348e6-fd63-47f6-ecfc-2f5f8eec1ea3"
      },
      "source": [
        "print(type_data)"
      ],
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7I7TlZiDzd5m",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "862e1c9f-be8f-41be-aa60-cb0e7b5b4dce"
      },
      "source": [
        "print(time_data[55:])"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[10.7141071618, 10.913673260273455, 11.113239446732196, 11.312805256060827, 11.512370697256241, 11.711936451266286, 11.911501342332627, 12.111066605743169, 12.310632010067888, 12.510197264535384, 12.709763082492131, 12.909328896609559, 13.108893730582944, 13.308458567881356, 13.508023458141153, 13.707587908539477, 13.907153169993366, 14.106718026284085, 14.30628293231913, 14.5058472636904, 14.705411627178606, 14.90497652672333, 15.10454138251613, 15.30410640430752, 15.50367104334718, 15.703233868031827, 15.902798161316024, 16.102350299049615, 16.301916478274237, 16.5014824334493, 16.701046128089285, 16.900611653780604, 17.100177492758885, 17.299743776100154, 17.49930818315491, 17.69887358304758, 17.898437715617096, 18.098003311104254, 18.297568729119867, 18.497134487783136, 18.69669933596674, 18.89626475172682, 19.095829150486956, 19.295394005801658, 19.494958901729117, 19.694523734143225, 19.8940882937542, 20.09365405072557, 20.293218032896313, 20.492783966946394, 20.69234915497717, 20.89191075136246, 21.091475725361924, 21.291039109305984, 21.490601478358442, 21.69016360506244, 21.88972701883466, 22.089289138495957, 22.28885354785711, 22.48841691094027, 22.68798140175235, 22.88754532230163, 23.087107117950552, 23.286669431030653, 23.48623048388419, 23.685794713375532, 23.885359240870248, 24.08492261393607, 24.284487185489738, 24.484050981007474, 24.68361498573281, 24.883178195164398, 25.082742231398864, 25.282306903110857, 25.48187074795346, 25.681434632204727, 25.880998630061896, 26.080562538709106, 26.280126499620735, 26.479690402079587, 26.679254349306188, 26.878818261873622, 27.07837928683134, 27.277942298698022, 27.477506263109102, 27.677067455393253, 27.876629502644384, 28.07619162586766, 28.275753569729627, 28.4753156931872, 28.674877578303313, 28.874439557062402, 29.074002554112948, 29.273566367926033, 29.473130232024165, 29.67269412142619, 29.87225251104981, 30.07181633890537, 30.27137846085058, 30.470939681010794, 30.67049815725027]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VDyxQacezk8P",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "difference = []\n",
        "for j in range(55,155):\n",
        "    difference.append(time_data[j+1]-time_data[j])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KVmlqYeQ-4Wy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from math import sqrt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBq-iACe_HJE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "time_data_origin = data_process(\"time-test.txt\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JebVNwyX-_--",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "340b371d-8c6f-45a5-edcd-4793ea109ec6"
      },
      "source": [
        "print(sqrt(mean_squared_error(time_data[55:], time_data_origin[0][55:])))"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.3264376927522263\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j1mH82B8LIfW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "outputId": "4d622ed8-1e6c-4934-ea41-03f663322128"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(range(100),difference)\n",
        "plt.ylim(top=0.4, bottom=0.0)\n",
        "plt.show()"
      ],
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1twgX0KLyxt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        },
        "outputId": "ef28aef1-b075-4bd9-f663-edd983eda786"
      },
      "source": [
        "print(difference)"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0.19956609847345597, 0.1995661864587408, 0.19956580932863055, 0.1995654411954142, 0.19956575401004528, 0.19956489106634123, 0.19956526341054115, 0.19956540432471925, 0.19956525446749573, 0.19956581795674744, 0.19956581411742746, 0.1995648339733851, 0.19956483729841246, 0.19956489025979707, 0.1995644503983236, 0.19956526145388942, 0.19956485629071885, 0.19956490603504484, 0.1995643313712705, 0.1995643634882054, 0.19956489954472367, 0.1995648557928007, 0.1995650217913898, 0.19956463903966082, 0.19956282468464615, 0.19956429328419745, 0.19955213773359048, 0.19956617922462172, 0.19956595517506415, 0.19956369463998413, 0.19956552569131958, 0.1995658389782804, 0.19956628334126947, 0.19956440705475487, 0.19956539989266986, 0.19956413256951677, 0.19956559548715802, 0.199565418015613, 0.19956575866326887, 0.19956484818360565, 0.19956541576008036, 0.19956439876013476, 0.19956485531470136, 0.19956489592745896, 0.19956483241410794, 0.19956455961097674, 0.19956575697136714, 0.19956398217074423, 0.1995659340500815, 0.19956518803077472, 0.19956159638529058, 0.1995649739994647, 0.19956338394406004, 0.19956236905245817, 0.19956212670399864, 0.19956341377221776, 0.199562119661298, 0.19956440936115172, 0.19956336308316125, 0.1995644908120795, 0.19956392054928074, 0.19956179564892196, 0.19956231308010075, 0.19956105285353587, 0.19956422949134378, 0.1995645274947151, 0.19956337306582128, 0.1995645715536689, 0.1995637955177365, 0.1995640047253353, 0.199563209431588, 0.1995640362344666, 0.1995646717119932, 0.19956384484260425, 0.19956388425126548, 0.19956399785716883, 0.1995639086472103, 0.19956396091162887, 0.19956390245885203, 0.19956394722660065, 0.19956391256743444, 0.19956102495771688, 0.19956301186668313, 0.19956396441108026, 0.19956119228415048, 0.19956204725113125, 0.19956212322327715, 0.19956194386196557, 0.19956212345757152, 0.19956188511611472, 0.199561978759089, 0.19956299705054548, 0.19956381381308574, 0.1995638640981312, 0.1995638894020253, 0.19955838962361838, 0.19956382785556315, 0.19956212194520973, 0.19956122016021283, 0.19955847623947776]\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}